{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2737e25",
   "metadata": {},
   "source": [
    "# ðŸ§¬ scIDiff: Single-cell Inverse Diffusion\n",
    "\n",
    "A demo of using DDPMs for denoising and inverse design of scRNA-seq profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b162c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if running in Colab)\n",
    "# !pip install torch torchvision torchaudio\n",
    "# !pip install scanpy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scanpy as sc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7bd844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load example single-cell data\n",
    "adata = sc.datasets.pbmc3k()\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "sc.pp.highly_variable_genes(adata, n_top_genes=1000)\n",
    "adata = adata[:, adata.var['highly_variable']]\n",
    "data = adata.X.toarray().astype(np.float32)\n",
    "print(\"Shape:\", data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa6cf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1000\n",
    "beta = np.linspace(1e-4, 0.02, T)\n",
    "alpha = 1 - beta\n",
    "alpha_hat = np.cumprod(alpha)\n",
    "\n",
    "plt.plot(alpha_hat)\n",
    "plt.title(\"Cumulative Alpha Schedule\")\n",
    "plt.xlabel(\"Timestep\")\n",
    "plt.ylabel(\"Alpha Hat\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd18dbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, dim)\n",
    "        )\n",
    "    def forward(self, x, t):\n",
    "        return self.net(x)\n",
    "\n",
    "model = MLP(data.shape[1])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897efdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_sample(x_0, t, noise):\n",
    "    alpha_t = torch.tensor(alpha_hat[t], dtype=torch.float32).unsqueeze(1)\n",
    "    return torch.sqrt(alpha_t) * x_0 + torch.sqrt(1 - alpha_t) * noise\n",
    "\n",
    "# Convert data\n",
    "x_0 = torch.tensor(data[:512])\n",
    "for step in range(1000):\n",
    "    t = torch.randint(0, T, (x_0.size(0),))\n",
    "    noise = torch.randn_like(x_0)\n",
    "    x_t = q_sample(x_0, t, noise)\n",
    "    noise_pred = model(x_t, t)\n",
    "    loss = F.mse_loss(noise_pred, noise)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if step % 100 == 0:\n",
    "        print(f\"Step {step}, Loss: {loss.item():.4f}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
